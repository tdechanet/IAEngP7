{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_parquet(\"dataframes/eda.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "\n",
    "\tdef __init__(self, texts, labels, tokenizer, max_length):\n",
    "\t\tself.texts = texts\n",
    "\t\tself.labels = labels\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.max_length = max_length\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.texts)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\ttext = self.texts[idx]\n",
    "\t\tlabel = self.labels[idx]\n",
    "\t\tencoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "\t\treturn {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'target': torch.tensor(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "\t\n",
    "\tdef __init__(self, bert_model_name, num_classes):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.bert = BertModel.from_pretrained(bert_model_name)\n",
    "\t\tself.dropout = nn.Dropout(0.1)\n",
    "\t\tself.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\t\n",
    "\tdef forward(self, input_ids, attention_mask):\n",
    "\t\toutputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\t\tpooled_output = outputs.pooler_output\n",
    "\t\tx = self.dropout(pooled_output)\n",
    "\t\tlogits = self.fc(x)\n",
    "\t\treturn logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "\tmodel.train()\n",
    "\n",
    "\tfor batch in tqdm(data_loader):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tinput_ids = batch[\"input_ids\"].to(device)\n",
    "\t\tattention_mask = batch[\"attention_mask\"].to(device)\n",
    "\t\tlabels = batch[\"target\"].to(device)\n",
    "\n",
    "\t\twith torch.amp.autocast(device_type=str(device)):\n",
    "\t\t\toutputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\t\t\tloss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\tscheduler.step()\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "\tmodel.eval()\n",
    "\tpredictions = []\n",
    "\tactual_labels = []\n",
    "\ttotal_loss = 0\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tfor batch in data_loader:\n",
    "\t\t\tinput_ids = batch[\"input_ids\"].to(device)\n",
    "\t\t\tattention_mask = batch[\"attention_mask\"].to(device)\n",
    "\t\t\tlabels = batch[\"target\"].to(device)\n",
    "\n",
    "\t\t\toutputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\t\t\t_, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "\t\t\tpredictions.extend(preds.cpu().tolist())\n",
    "\t\t\tactual_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "\t\t\tloss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "\t\t\ttotal_loss += loss.item() * input_ids.size(0)\n",
    "\n",
    "\tavg_loss = total_loss / len(data_loader.dataset)\n",
    "\treturn accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions), avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device, max_length=128):\n",
    "\tmodel.eval()\n",
    "\tencoding = tokenizer(text, return_tensors=\"pt\", max_length=max_length, padding=\"max_length\", truncation=True)\n",
    "\tinput_ids = encoding[\"input_ids\"].to(device)\n",
    "\tattention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\toutputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\t\t_, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "\treturn \"positive\" if preds.item() == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'bert-base-uncased'\n",
    "num_classes = 2\n",
    "max_length = 64\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "learning_rate = 2e-5\n",
    "\n",
    "texts = df[\"content\"]\n",
    "labels = df[\"target\"]\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_texts = train_texts.to_list()\n",
    "val_texts = val_texts.to_list()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "experiment_name = \"Réalisez une analyse de sentiments grâce au Deep Learning\"\n",
    "mlflow.set_experiment(experiment_name=experiment_name)\n",
    "\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "best_loss_accuracy = 0\n",
    "patience_counter = 0\n",
    "PATIENCE = 1\n",
    "MODEL_PATH = \"models/best_bert_model.pth\"\n",
    "\n",
    "# with mlflow.start_run(run_name=\"BERT_base_uncased\"):\n",
    "\n",
    "# \tloss = 0\n",
    "# \taccuracy = 0\n",
    "\n",
    "# \tfor epoch in range(num_epochs):\n",
    "\n",
    "# \t\tprint(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "# \t\ttrain(model, train_dataloader, optimizer, scheduler, device)\n",
    "\n",
    "# \t\taccuracy, report, loss = evaluate(model, val_dataloader, device)\n",
    "# \t\tprint(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "# \t\tprint(f\" Validation Loss: {loss:.4f}\")\n",
    "# \t\tprint(report)\n",
    "\n",
    "# \t\tmlflow.log_metric(f\"test_loss\", loss, step=epoch+1)\n",
    "# \t\tmlflow.log_metric(f\"test_acc\", float(accuracy), step=epoch+1)\n",
    "\n",
    "# \t\tif loss < best_loss:\n",
    "# \t\t\tbest_loss = loss\n",
    "# \t\t\tbest_loss_accuracy = accuracy\n",
    "# \t\t\tpatience_counter = 0\n",
    "\n",
    "# \t\t\ttorch.save(model.state_dict(), MODEL_PATH)\n",
    "\t\t\n",
    "# \t\telse:\n",
    "# \t\t\tpatience_counter += 1\n",
    "\t\t\t\n",
    "# \t\t\tif patience_counter >= PATIENCE:\n",
    "# \t\t\t\tprint(\"Early Stopping Trigered\")\n",
    "# \t\t\t\tbreak\n",
    "\n",
    "# \tmodel.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "# \tmlflow.log_metric(\"final_test_loss\", best_loss)\n",
    "# \tmlflow.log_metric(\"final_test_acc\", float(best_loss_accuracy))\n",
    "\n",
    "# \tinput_example = train_texts[1]\n",
    "# \toutput_example = predict_sentiment(input_example, model, tokenizer, device, max_length)\n",
    "\n",
    "# \tmlflow.pytorch.log_model(\n",
    "# \t\tmodel,\n",
    "# \t\tname=\"BERT\",\n",
    "# \t\tsignature=mlflow.models.signature.infer_signature(input_example, output_example),\n",
    "# \t)\n",
    "\n",
    "# \tparams = {\n",
    "# \t\t\"model_type\": \"Torch_BERT\",\n",
    "# \t\t\"bert_model_name\" : bert_model_name,\n",
    "# \t\t\"num_classes\" : num_classes,\n",
    "# \t\t\"max_length\" : max_length,\n",
    "# \t\t\"batch_size\" : batch_size,\n",
    "# \t\t\"num_epochs\" : num_epochs,\n",
    "# \t\t\"learning_rate\" : learning_rate\n",
    "# \t}\n",
    "\n",
    "# \tmlflow.log_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.onnx import export\n",
    "\n",
    "# model.load_state_dict(torch.load(MODEL_PATH))\n",
    "# model.to('cpu')\n",
    "# model.eval()\n",
    "\n",
    "# DTYPE = torch.long\n",
    "\n",
    "# dummy_input_ids = torch.randint(0, 10000, (1, max_length), dtype=DTYPE, device='cpu') \n",
    "\n",
    "# dummy_attention_mask = torch.ones((1, max_length), dtype=DTYPE, device='cpu') \n",
    "# dummy_args = (dummy_input_ids,)\n",
    "\n",
    "# dummy_kwargs = {\"attention_mask\": dummy_attention_mask}\n",
    "\n",
    "# dynamic_shapes = {\n",
    "#     \"input_ids\": {0: \"batch_size\"}, \n",
    "#     \"attention_mask\": {0: \"batch_size\"}\n",
    "# }\n",
    "\n",
    "# input_names = [\"input_ids\", \"attention_mask\"]\n",
    "\n",
    "# export(\n",
    "#     model,\n",
    "#     dummy_args,\n",
    "#     \"models/bert_reduced_model.onnx\",\n",
    "#     kwargs=dummy_kwargs,\n",
    "#     input_names=input_names,\n",
    "#     output_names=[\"output\"],\n",
    "#     dynamic_shapes=dynamic_shapes\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load(MODEL_PATH))\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# model_res = []\n",
    "\n",
    "# for line in tqdm(val_dataloader.dataset):\n",
    "\n",
    "# \tpred = model(\n",
    "# \t\tline[\"input_ids\"].unsqueeze(0).to(device),\n",
    "# \t\tline[\"attention_mask\"].unsqueeze(0).to(device)\n",
    "# \t)\n",
    "\n",
    "# \tmodel_pred = pred.cpu().detach().numpy()[0]\n",
    "# \tmodel_res.append(0 if model_pred[0] > model_pred[1] else 1)\n",
    "\n",
    "\n",
    "# onnx_model = rt.InferenceSession(\"models/bert_reduced_model.onnx\", providers=[\"CUDAExecutionProvider\"])\n",
    "# onnx_res = []\n",
    "\n",
    "# for line in tqdm(val_dataloader.dataset):\n",
    "\n",
    "# \tonnx_input = {\n",
    "# \t\t\"input_ids\":np.array([line[\"input_ids\"]]),\n",
    "# \t\t\"attention_mask\":np.array([line[\"attention_mask\"]])\n",
    "# \t}\n",
    "\n",
    "# \tonnx_pred = onnx_model.run([\"output\"], onnx_input)[0][0]\n",
    "\n",
    "# \tonnx_res.append(0 if onnx_pred[0] > onnx_pred[1] else 1)\n",
    "\n",
    "\n",
    "# onnx_cpu_model = rt.InferenceSession(\"models/bert_reduced_model.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "# onnx_cpu_res = []\n",
    "\n",
    "# for line in tqdm(val_dataloader.dataset):\n",
    "\n",
    "# \tonnx_cpu_input = {\n",
    "# \t\t\"input_ids\":np.array([line[\"input_ids\"]]),\n",
    "# \t\t\"attention_mask\":np.array([line[\"attention_mask\"]])\n",
    "# \t}\n",
    "\n",
    "# \tonnx_cpu_pred = onnx_cpu_model.run([\"output\"], onnx_cpu_input)[0][0]\n",
    "\n",
    "# \tonnx_cpu_res.append(0 if onnx_cpu_pred[0] > onnx_cpu_pred[1] else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Accuracy score du modèle BERT : \", accuracy_score(val_labels, model_res))\n",
    "# print(\"Accuracy score du modèle ONNX : \", accuracy_score(val_labels, onnx_res))\n",
    "# print(\"Accuracy score du modèle ONNX sur CPU : \", accuracy_score(val_labels, onnx_cpu_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = rt.InferenceSession(\"models/bert_reduced_model.onnx\", providers=[\"CUDAExecutionProvider\"])\n",
    "onnx_res = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"ONNX_model\"):\n",
    "\tfor line in tqdm(val_dataloader.dataset):\n",
    "\n",
    "\t\tonnx_input = {\n",
    "\t\t\t\"input_ids\":np.array([line[\"input_ids\"]]),\n",
    "\t\t\t\"attention_mask\":np.array([line[\"attention_mask\"]])\n",
    "\t\t}\n",
    "\n",
    "\t\tonnx_pred = onnx_model.run([\"output\"], onnx_input)[0][0]\n",
    "\n",
    "\t\tonnx_res.append(0 if onnx_pred[0] > onnx_pred[1] else 1)\n",
    "\n",
    "\tmlflow.log_metric(\"final_test_acc\", float(accuracy_score(val_labels, onnx_res)))\n",
    "\n",
    "\tinput_example = train_texts[1]\n",
    "\toutput_example = onnx_pred\n",
    "\n",
    "\tonnx_model_proto = onnx.load(\"models/bert_reduced_model.onnx\")\n",
    "\tmlflow.onnx.log_model(\n",
    "\t\tonnx_model_proto,\n",
    "\t\tname=\"BERT_ONNX\",\n",
    "\t\tsignature=mlflow.models.signature.infer_signature(input_example, output_example),\n",
    "\t)\n",
    "\n",
    "\ttokenizer.save_pretrained(\"tokenizer_artifacts\")\n",
    "\tmlflow.log_artifacts(\"tokenizer_artifacts\", artifact_path=\"tokenizer\")\n",
    "\n",
    "\tparams = {\n",
    "\t\t\"model_type\": \"Torch_BERT_ONNX\",\n",
    "\t\t\"bert_model_name\" : bert_model_name,\n",
    "\t\t\"num_classes\" : num_classes,\n",
    "\t\t\"max_length\" : max_length,\n",
    "\t\t\"batch_size\" : batch_size,\n",
    "\t\t\"num_epochs\" : num_epochs,\n",
    "\t\t\"learning_rate\" : learning_rate\n",
    "\t}\n",
    "\n",
    "\tmlflow.log_params(params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAEngP7-oYMYfi1b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
