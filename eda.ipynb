{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Analyse exploratoire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous allons explorer la base de données disponible avec ce lien : https://www.kaggle.com/datasets/kazanova/sentiment140. Elle contient les tweets d'utilisateurs ainsi que le sentiment qu'il laisse transparaître, c'est à dire positif ou négatif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Premier coup d'oeil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Commençons par survoler notre base de données. Le csv n'a pas de titre, nous allons donc les définir nous mêmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "df = pl.read_csv(\"data/training.csv\", encoding=\"latin-1\", has_header=False)\n",
    "df.columns = [\"target\", \"id\", \"date\", \"query\", \"name\", \"content\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "On remarque que les colonnes ne sont pas nommées dans le fichier csv, ce qui a donc eu pour effet d'avoir utilisé les données de la première ligne comme titre. Vu qu'il y a plus d'un million de lignes, nous pourrions nous contenter de renommer chaque colonne sans récupérer la première ligne, mais même si ça aura peu d'impact sur notre programme, faisons les choses bien et récupérons là."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Maintenant que nous nous sommes occupés des titres, observons le nombre de valeurs différentes de chaque colonne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.all().n_unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "La colonne \"query\" ne contient qu'une seule valeur: \"NO_QUERY\". Elle ne pourra donc pas nous aider à entraîner un modèle de machine learning, nous pouvons donc la supprimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Un autre détail nous interpelle, il y a 1 600 000 lignes, mais pourtant il n'y a que 1 598 315 \"id\" différents. Assurons-nous donc qu'il n'y a pas de doublons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Les lignes sont pourtant toutes différentes. Regardons plus en détail deux lignes contenant le même id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_ids = df.filter(pl.col(\"id\").is_duplicated()).sort(\"id\")\n",
    "dup_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "On comprend mieux ce qu'il se passe. En fait les \"id\" en doublons sont les mêmes lignes mais avec deux target différentes, ce qui est une anomalie. Nous allons donc les supprimer, étant donné qu'elles ne concernent que 0,2% de nos données, ce n'est pas très grave. Profitons-en au passage pour changer ses valeurs de 0 et 4 au 0 et 1 traditonnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_ids_list = dup_ids[\"id\"].unique().implode()\n",
    "df = df.filter(~df[\"id\"].is_in(dup_ids_list))\n",
    "\n",
    "df = df.with_columns(pl.col(\"target\").replace(4, 1).alias(\"target\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Maintenant que nous avons réglé ce problème d'ids récurrents, nous allons modifier le type de données de la colonne \"date\" de string à datetime, ce qui la rendra plus facile à manipuler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(pl.col(\"date\").str.to_datetime(\"%a %b %d %H:%M:%S %Z %Y\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "On obtient quelques informations intéressantes. En premier lieu, notre \"target\" est bien distribué, ce qui évitera des biais lors des entraînements de nos modèles. Ensuite, le premier et le dernier tweet sont espacés de à peu près 11 semaines, mais que plus de 50% d'entre eux ont été récupérés sur une période de seulement 3 semaines. Il faudra être attentif à ça, car des tweets pourraient être biasiés à cause d'un événement. Et pour finir, on se rend compte en regardant \"content\" que certains messages sont très bizarres, potentiellement dus au formatage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Commençons par visualiser la \"target\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "target_count = df[\"target\"].value_counts()\n",
    "\n",
    "fig = px.bar(\n",
    "    target_count,\n",
    "    x=\"target\",\n",
    "    y=\"count\",\n",
    "    title=\"Distribution de la target\",\n",
    "    width=800\n",
    ")\n",
    "\n",
    "grap_title = {\n",
    "        \"size\":30,\n",
    "        \"weight\": 600\n",
    "\t}\n",
    "\n",
    "fig.update_layout(\n",
    "\ttitle_font = grap_title,\n",
    "    title_x = 0.5,\n",
    "    xaxis_tick0 = 0,\n",
    "    xaxis_dtick = 1,\n",
    "    yaxis_showticklabels = False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "On remarque qu'elle est parfaitement distribué."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Ceci fait, penchons nous sur la distribution des dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bins = (\n",
    "    df.with_columns(\n",
    "        pl.col(\"date\").dt.truncate(\"1w\").alias(\"week\")\n",
    "    )\n",
    "    .group_by(\"week\")\n",
    "    .len()\n",
    ")\n",
    "\n",
    "fig = px.bar(\n",
    "    df_bins,\n",
    "    x=\"week\",\n",
    "    y=\"len\",\n",
    "    title=\"Distribution des dates\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "\ttitle_font = grap_title,\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Fréquence\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "On se rend compte que près de trois quarts des données ont été récupérées sur une période de seulement 4 semaines. Comme je l'ai dit précédemment, il faudra y être attentif."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## Contenu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Occupons-nous maintenant des lignes dont les tweets contiennent des caractères non ASCII. Effectivement, ils poseront problème au bon fonctionnement de nos modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ascii = df.filter(~df[\"content\"].str.contains(r\"^[\\x00-\\x7F]*$\"))\n",
    "pl.Config.set_fmt_str_lengths(50)\n",
    "df_ascii[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Il y a 14 500 lignes contenant des caractères non ASCII. C'est relativement peu, nous pouvons donc nous permettre de les supprimer. Cependant, en regardant ces lignes, on peut se rendre compte que tous les tweets ne sont pas en anglais. Cela risque d'être un problème et nous devons les trouver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Tout d'abord, supprimons les lignes que nous venons de trouver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(~df[\"id\"].is_in(df_ascii[\"id\"].implode()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Maintenant, réglons ce problème de langues. Pour ça nous allons installer la librairie \"Pycld2\". Elle permet d'automatiquement détecter les langues utilisées dans un texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycld2 as cld2\n",
    "\n",
    "def detect_lang_batch(batch):\n",
    "    \n",
    "    out = []\n",
    "    for content in batch:\n",
    "        \n",
    "        try:\n",
    "            _, _, details = cld2.detect(content)\n",
    "            out.append(details[0][1])\n",
    "\n",
    "        except Exception as e:\n",
    "            out.append(f\"__ERROR__:{type(e).__name__}:{str(e)[:200]}\")\n",
    "\n",
    "    return pl.Series(out)\n",
    "\n",
    "df = df.with_columns(\n",
    "    pl.col(\"content\").map_batches(detect_lang_batch, return_dtype=pl.Utf8, returns_scalar=False).alias(\"lang_safe\")\n",
    ")\n",
    "\n",
    "df.filter(pl.col(\"lang_safe\").str.starts_with(\"__ERROR__\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "On se rend compte que quelques lignes comportent des erreurs d'encodage, mais il n'y en a que 16. Nous pouvons donc nous contenter de les supprimer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Regardons maintenant le nombre de lignes ayant été détectées écrites en anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lang_safe\"].value_counts().sort(\"count\", descending=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Il restera plus de 1 500 000 lignes après la suppression des lignes non anglaises. C'est largement suffisant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df[\"lang_safe\"] == \"en\").drop(\"lang_safe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Jetons un oeil à la longueur des tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_length = df[\"content\"].str.len_bytes()\n",
    "\n",
    "fig = px.histogram(content_length, title=\"Distribution de la longueur des tweets\")\n",
    "\n",
    "fig.update_layout(\n",
    "\ttitle_font = grap_title,\n",
    "    title_x = 0.5,\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Fréquence\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "On remarque que les tweets ont une longueur assez bien répartie autour de 40, avec un pic autour d'une longueur de 130 caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Nous allons maintenant afficher un nuage de mots afin de visualiser les mots les plus utilisés. Avant ceci, nous allons bien faire attention à ne pas considérer les caractères, tels que \", qui ne sont pas très représentatifs du contenu des tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import html\n",
    "\n",
    "wrd_cld_df = df.with_columns(pl.col(\"content\").map_elements(html.unescape))\n",
    "\n",
    "wrd_cld = WordCloud(width=800, height=400, background_color=\"white\")\n",
    "wrd_cld.generate(\" \".join(wrd_cld_df[\"content\"].to_list()))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.imshow(wrd_cld, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Nuage de mots des tweets\", fontsize=30, weight=\"bold\", pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "On remarque clairement des mots qui apparaissent très souvent mais ce qui serait encore mieux, étant donné que l'on veut lier un sentiment positif ou négatif à ces mots, serait qu'on divise notre tableau de données en deux avec les tweets positifs d'un côté et les tweets négatifs de l'autre et qu'on étudie la différence des mots retrouvés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrd_cld_df_0 = wrd_cld_df.filter(pl.col(\"target\") == 0)\n",
    "wrd_cld_df_1 = wrd_cld_df.filter(pl.col(\"target\") == 1)\n",
    "\n",
    "wrd_cld_0 = WordCloud(width=800, height=400, background_color=\"white\")\n",
    "wrd_cld_0.generate(\" \".join(wrd_cld_df_0[\"content\"].to_list()))\n",
    "\n",
    "wrd_cld_1 = WordCloud(width=800, height=400, background_color=\"white\")\n",
    "wrd_cld_1.generate(\" \".join(wrd_cld_df_1[\"content\"].to_list()))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wrd_cld_0, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Tweets négatifs\", fontsize=30, weight=\"bold\", pad=20)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wrd_cld_1, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Tweets positifs\", fontsize=30, weight=\"bold\", pad=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Nous remarquons que certains mots se retrouvent à part égale dans les deux types de tweets (going, now, today...), mais aussi que certains mots sont clairement négatifs (work, want, miss...), et d'autres clairement positifs (love, thank, lol...). Ceci nous rassure sur la faisabilité de la mission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IAEngP7-oYMYfi1b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
